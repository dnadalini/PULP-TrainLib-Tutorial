# Further optimization: PULP-TrainLib's FP16 kernels

In this last tutorial we consider the case of a Conv2D layer and exploit hardware-aware techniques to maximize the performances of the inner computational kernels.

## SIMD Units, Multicore & Unrolling


## The SIMD case


## Conv2D Optimization


## References

> D. Nadalini, M. Rusci, L. Benini, and F. Conti, "Reduced Precision Floating-Point Optimization for Deep Neural Network On-Device Learning on MicroControllers" [ArXiv Pre-Print](https://arxiv.org/abs/2305.19167)
